#!/usr/bin/env python3
"""
Deep Functional Test for Marketing Agent Platform

This script tests whether the platform actually DELIVERS VALUE, not just renders pages.
It verifies:
1. Brand Onboarding - Does AI extract real Brand DNA from a website?
2. Campaign Execution - Do agents generate actual deliverables?
3. AI Chat Quality - Does it use the knowledge base properly?
4. Kata Lab - Do video/influencer/script features actually work?
5. Deliverables - Are actual assets generated and downloadable?
"""

import asyncio
import httpx
import json
import time
from datetime import datetime

BASE_URL = "http://localhost:8000"

# Test data
TEST_BRAND = {
    "name": "Nike",
    "website": "https://www.nike.com",
    "industry": "Athletic Footwear & Apparel"
}

class DeepFunctionalTest:
    def __init__(self):
        self.client = httpx.AsyncClient(timeout=120.0)  # Long timeout for AI operations
        self.user_id = None
        self.organization_id = None
        self.access_token = None
        self.campaign_id = None
        self.results = {
            "brand_onboarding": {"status": "not_tested", "details": {}},
            "campaign_execution": {"status": "not_tested", "details": {}},
            "ai_chat": {"status": "not_tested", "details": {}},
            "kata_lab": {"status": "not_tested", "details": {}},
            "deliverables": {"status": "not_tested", "details": {}}
        }
    
    def _auth_headers(self):
        """Get authorization headers"""
        if self.access_token:
            return {"Authorization": f"Bearer {self.access_token}"}
        return {}
    
    async def setup(self):
        """Create test user and organization"""
        print("\n" + "="*60)
        print("SETUP: Creating test user and organization")
        print("="*60)
        
        # Register user
        timestamp = int(time.time())
        email = f"deeptest_{timestamp}@example.com"
        
        response = await self.client.post(f"{BASE_URL}/api/auth/register", json={
            "email": email,
            "password": "TestPass123!",
            "name": "Deep Test User",
            "organization_name": TEST_BRAND["name"]
        })
        
        if response.status_code == 200:
            data = response.json()
            # Extract from TokenResponse format
            self.access_token = data.get("access_token")
            user_data = data.get("user", {})
            self.user_id = user_data.get("id")
            self.organization_id = user_data.get("organization_id")
            print(f"‚úÖ User created: {email}")
            print(f"   User ID: {self.user_id}")
            print(f"   Organization ID: {self.organization_id}")
            print(f"   Access Token: {self.access_token[:20]}..." if self.access_token else "   No token!")
            return True
        else:
            print(f"‚ùå Failed to create user: {response.status_code}")
            print(f"   Response: {response.text}")
            return False
    
    async def test_brand_onboarding(self):
        """
        DEEP TEST 1: Brand Onboarding
        
        Tests whether the platform can:
        - Crawl a real website (nike.com)
        - Extract meaningful Brand DNA
        - Populate knowledge base with quality content
        """
        print("\n" + "="*60)
        print("DEEP TEST 1: Brand Onboarding")
        print("="*60)
        print(f"Testing with: {TEST_BRAND['website']}")
        
        try:
            # Trigger onboarding
            print("\nüì° Triggering brand onboarding pipeline...")
            response = await self.client.post(
                f"{BASE_URL}/api/onboarding/start",
                json={
                    "domain": "nike.com",
                    "company_name": TEST_BRAND["name"]
                },
                headers=self._auth_headers()
            )
            
            if response.status_code != 200:
                print(f"‚ùå Onboarding failed to start: {response.status_code}")
                print(f"   Response: {response.text}")
                self.results["brand_onboarding"]["status"] = "failed"
                self.results["brand_onboarding"]["details"]["error"] = response.text
                return False
            
            onboarding_data = response.json()
            print(f"‚úÖ Onboarding started")
            
            # Wait for onboarding to complete (poll status)
            max_wait = 120  # 2 minutes max
            start_time = time.time()
            
            while time.time() - start_time < max_wait:
                status_response = await self.client.get(
                    f"{BASE_URL}/api/onboarding/status/{self.organization_id}",
                    headers=self._auth_headers()
                )
                
                if status_response.status_code == 200:
                    status_data = status_response.json()
                    stage = status_data.get("stage", "unknown")
                    progress = status_data.get("progress", 0)
                    
                    print(f"   Stage: {stage} ({progress*100:.0f}%)")
                    
                    if stage == "complete":
                        print("‚úÖ Onboarding completed!")
                        break
                    elif stage == "failed":
                        print(f"‚ùå Onboarding failed: {status_data.get('error')}")
                        self.results["brand_onboarding"]["status"] = "failed"
                        return False
                
                await asyncio.sleep(5)
            
            # Now verify the knowledge base has quality content
            print("\nüìä Verifying Knowledge Base content...")
            kb_response = await self.client.get(
                f"{BASE_URL}/api/organizations/{self.organization_id}/knowledge-base",
                headers=self._auth_headers()
            )
            
            if kb_response.status_code != 200:
                print(f"‚ùå Failed to get knowledge base: {kb_response.status_code}")
                self.results["brand_onboarding"]["status"] = "partial"
                return False
            
            kb_data = kb_response.json()
            
            # Evaluate quality of extracted data
            quality_checks = {
                "has_brand_name": bool(kb_data.get("brand_data", {}).get("name")),
                "has_description": bool(kb_data.get("brand_data", {}).get("description")),
                "has_voice_tone": bool(kb_data.get("brand_data", {}).get("voice", {}).get("tone")),
                "has_values": len(kb_data.get("brand_data", {}).get("values", [])) > 0,
                "has_industry": bool(kb_data.get("market_data", {}).get("industry")),
                "has_competitors": len(kb_data.get("market_data", {}).get("competitors", [])) > 0,
                "has_audience_segments": len(kb_data.get("audiences_data", {}).get("segments", [])) > 0,
                "has_products": len(kb_data.get("offerings_data", {}).get("products", [])) > 0,
                "has_brand_dna": bool(kb_data.get("brand_dna"))
            }
            
            print("\nüìã Knowledge Base Quality Check:")
            passed = 0
            for check, result in quality_checks.items():
                status = "‚úÖ" if result else "‚ùå"
                print(f"   {status} {check.replace('_', ' ').title()}")
                if result:
                    passed += 1
            
            quality_score = passed / len(quality_checks)
            print(f"\n   Quality Score: {quality_score*100:.0f}% ({passed}/{len(quality_checks)})")
            
            # Show actual extracted data
            print("\nüìù Extracted Brand DNA:")
            brand_data = kb_data.get("brand_data", {})
            print(f"   Name: {brand_data.get('name', 'N/A')}")
            print(f"   Description: {brand_data.get('description', 'N/A')[:100]}...")
            print(f"   Voice Tone: {brand_data.get('voice', {}).get('tone', 'N/A')}")
            print(f"   Values: {brand_data.get('values', [])}")
            
            market_data = kb_data.get("market_data", {})
            print(f"\n   Industry: {market_data.get('industry', 'N/A')}")
            print(f"   Competitors: {[c.get('name') for c in market_data.get('competitors', [])]}")
            
            audiences = kb_data.get("audiences_data", {}).get("segments", [])
            print(f"\n   Audience Segments: {[a.get('name') for a in audiences]}")
            
            self.results["brand_onboarding"]["status"] = "passed" if quality_score >= 0.7 else "partial"
            self.results["brand_onboarding"]["details"] = {
                "quality_score": quality_score,
                "checks": quality_checks,
                "brand_name": brand_data.get("name"),
                "industry": market_data.get("industry"),
                "num_competitors": len(market_data.get("competitors", [])),
                "num_segments": len(audiences)
            }
            
            return quality_score >= 0.7
            
        except Exception as e:
            print(f"‚ùå Exception during onboarding test: {e}")
            self.results["brand_onboarding"]["status"] = "error"
            self.results["brand_onboarding"]["details"]["error"] = str(e)
            return False
    
    async def test_campaign_execution(self):
        """
        DEEP TEST 2: Campaign Execution
        
        Tests whether the platform can:
        - Create a campaign
        - Execute it with AI agents
        - Generate actual deliverables (copy, images, etc.)
        """
        print("\n" + "="*60)
        print("DEEP TEST 2: Campaign Execution")
        print("="*60)
        
        try:
            # Create a campaign
            print("\nüìù Creating campaign...")
            campaign_data = {
                "name": "Nike Air Max 2026 Launch Campaign",
                "organization_id": self.organization_id,
                "campaign_type": "product_launch",
                "goal": "Launch the new Nike Air Max 2026 with maximum impact",
                "target_audience": "Athletes and sneaker enthusiasts aged 18-35",
                "platforms": ["instagram", "tiktok", "twitter"],
                "budget": 50000,
                "start_date": "2026-03-01",
                "end_date": "2026-04-30"
            }
            
            response = await self.client.post(
                f"{BASE_URL}/api/campaigns",
                json=campaign_data,
                headers=self._auth_headers()
            )
            
            if response.status_code not in [200, 201]:
                print(f"‚ùå Failed to create campaign: {response.status_code}")
                print(f"   Response: {response.text}")
                self.results["campaign_execution"]["status"] = "failed"
                return False
            
            campaign = response.json()
            self.campaign_id = campaign.get("id")
            print(f"‚úÖ Campaign created: {self.campaign_id}")
            
            # Execute the campaign
            print("\nüöÄ Executing campaign (triggering AI agents)...")
            exec_response = await self.client.post(
                f"{BASE_URL}/api/campaigns/{self.campaign_id}/execute",
                json={"organization_id": self.organization_id},
                headers=self._auth_headers()
            )
            
            if exec_response.status_code != 200:
                print(f"‚ùå Failed to execute campaign: {exec_response.status_code}")
                print(f"   Response: {exec_response.text}")
                self.results["campaign_execution"]["status"] = "failed"
                return False
            
            exec_data = exec_response.json()
            print(f"‚úÖ Campaign execution triggered")
            print(f"   Status: {exec_data.get('status')}")
            
            # Wait for execution to complete
            print("\n‚è≥ Waiting for AI agents to generate deliverables...")
            max_wait = 180  # 3 minutes max
            start_time = time.time()
            
            while time.time() - start_time < max_wait:
                status_response = await self.client.get(
                    f"{BASE_URL}/api/campaigns/{self.campaign_id}",
                    headers=self._auth_headers()
                )
                
                if status_response.status_code == 200:
                    status_data = status_response.json()
                    status = status_data.get("status", "unknown")
                    
                    print(f"   Campaign status: {status}")
                    
                    if status in ["completed", "complete"]:
                        print("‚úÖ Campaign execution completed!")
                        break
                    elif status == "failed":
                        print(f"‚ùå Campaign execution failed")
                        self.results["campaign_execution"]["status"] = "failed"
                        return False
                
                await asyncio.sleep(10)
            
            # Check for deliverables
            print("\nüì¶ Checking for generated deliverables...")
            deliverables_response = await self.client.get(
                f"{BASE_URL}/api/campaigns/{self.campaign_id}/deliverables",
                headers=self._auth_headers()
            )
            
            if deliverables_response.status_code != 200:
                print(f"‚ö†Ô∏è Could not fetch deliverables: {deliverables_response.status_code}")
                # Try alternative endpoint
                deliverables_response = await self.client.get(
                    f"{BASE_URL}/api/deliverables?campaign_id={self.campaign_id}",
                    headers=self._auth_headers()
                )
            
            deliverables = []
            if deliverables_response.status_code == 200:
                deliverables = deliverables_response.json()
                if isinstance(deliverables, dict):
                    deliverables = deliverables.get("deliverables", [])
            
            print(f"\nüìã Deliverables Generated: {len(deliverables)}")
            
            deliverable_types = {}
            for d in deliverables:
                d_type = d.get("type", "unknown")
                deliverable_types[d_type] = deliverable_types.get(d_type, 0) + 1
                print(f"   - {d.get('name', 'Unnamed')}: {d_type}")
            
            # Evaluate campaign execution quality
            quality_checks = {
                "campaign_created": bool(self.campaign_id),
                "execution_triggered": exec_data.get("status") in ["queued", "running", "completed"],
                "has_deliverables": len(deliverables) > 0,
                "has_copy": deliverable_types.get("copy", 0) > 0 or deliverable_types.get("text", 0) > 0,
                "has_images": deliverable_types.get("image", 0) > 0,
                "has_strategy": deliverable_types.get("strategy", 0) > 0 or deliverable_types.get("brief", 0) > 0
            }
            
            print("\nüìã Campaign Execution Quality Check:")
            passed = 0
            for check, result in quality_checks.items():
                status = "‚úÖ" if result else "‚ùå"
                print(f"   {status} {check.replace('_', ' ').title()}")
                if result:
                    passed += 1
            
            quality_score = passed / len(quality_checks)
            print(f"\n   Quality Score: {quality_score*100:.0f}% ({passed}/{len(quality_checks)})")
            
            self.results["campaign_execution"]["status"] = "passed" if quality_score >= 0.5 else "partial"
            self.results["campaign_execution"]["details"] = {
                "quality_score": quality_score,
                "checks": quality_checks,
                "num_deliverables": len(deliverables),
                "deliverable_types": deliverable_types
            }
            
            return quality_score >= 0.5
            
        except Exception as e:
            print(f"‚ùå Exception during campaign test: {e}")
            import traceback
            traceback.print_exc()
            self.results["campaign_execution"]["status"] = "error"
            self.results["campaign_execution"]["details"]["error"] = str(e)
            return False
    
    async def test_ai_chat(self):
        """
        DEEP TEST 3: AI Chat Quality
        
        Tests whether the AI chat:
        - Uses the brand's knowledge base
        - Provides contextually relevant responses
        - Can help with real marketing tasks
        """
        print("\n" + "="*60)
        print("DEEP TEST 3: AI Chat Quality")
        print("="*60)
        
        try:
            # Create a conversation
            print("\nüí¨ Creating conversation...")
            conv_response = await self.client.post(
                f"{BASE_URL}/api/chat/conversations",
                json={
                    "organization_id": self.organization_id,
                    "title": "Brand Strategy Discussion"
                },
                headers=self._auth_headers()
            )
            
            if conv_response.status_code not in [200, 201]:
                print(f"‚ùå Failed to create conversation: {conv_response.status_code}")
                self.results["ai_chat"]["status"] = "failed"
                return False
            
            conv_data = conv_response.json()
            conversation_id = conv_data.get("id")
            print(f"‚úÖ Conversation created: {conversation_id}")
            
            # Test questions that require brand knowledge
            test_questions = [
                {
                    "question": "What is our brand's core message and values?",
                    "expected_keywords": ["nike", "athletic", "sport", "just do it", "innovation", "performance"]
                },
                {
                    "question": "Who is our target audience and what are their pain points?",
                    "expected_keywords": ["athlete", "fitness", "performance", "comfort", "style"]
                },
                {
                    "question": "Write a short Instagram caption for our new product launch",
                    "expected_keywords": ["nike", "#", "launch", "new"]
                }
            ]
            
            chat_quality_scores = []
            
            for i, test in enumerate(test_questions):
                print(f"\nüì§ Question {i+1}: {test['question'][:50]}...")
                
                msg_response = await self.client.post(
                    f"{BASE_URL}/api/chat/conversations/{conversation_id}/messages?stream=false",
                    json={
                        "content": test["question"],
                        "organization_id": self.organization_id
                    },
                    headers=self._auth_headers()
                )
                
                if msg_response.status_code != 200:
                    print(f"   ‚ùå Failed to send message: {msg_response.status_code}")
                    continue
                
                response_data = msg_response.json()
                ai_response = (
                    response_data.get("assistant_message", {}).get("content", "")
                    or response_data.get("content", "")
                    or response_data.get("response", "")
                )
                
                if not ai_response:
                    print(f"   ‚ùå No AI response received")
                    continue
                
                print(f"üì• Response: {ai_response[:200]}...")
                
                # Check if response contains expected keywords
                response_lower = ai_response.lower()
                keywords_found = sum(1 for kw in test["expected_keywords"] if kw.lower() in response_lower)
                keyword_score = keywords_found / len(test["expected_keywords"])
                
                # Check response quality
                quality_indicators = {
                    "has_content": len(ai_response) > 50,
                    "not_error": "error" not in response_lower and "sorry" not in response_lower[:50],
                    "has_keywords": keyword_score > 0.3,
                    "is_relevant": any(kw in response_lower for kw in ["brand", "marketing", "audience", "campaign", "content"])
                }
                
                question_score = sum(quality_indicators.values()) / len(quality_indicators)
                chat_quality_scores.append(question_score)
                
                print(f"   Keywords found: {keywords_found}/{len(test['expected_keywords'])}")
                print(f"   Quality score: {question_score*100:.0f}%")
            
            # Overall chat quality
            avg_quality = sum(chat_quality_scores) / len(chat_quality_scores) if chat_quality_scores else 0
            
            print(f"\nüìã AI Chat Quality Summary:")
            print(f"   Average Quality Score: {avg_quality*100:.0f}%")
            print(f"   Questions Answered: {len(chat_quality_scores)}/{len(test_questions)}")
            
            self.results["ai_chat"]["status"] = "passed" if avg_quality >= 0.5 else "partial"
            self.results["ai_chat"]["details"] = {
                "quality_score": avg_quality,
                "questions_tested": len(test_questions),
                "questions_answered": len(chat_quality_scores)
            }
            
            return avg_quality >= 0.5
            
        except Exception as e:
            print(f"‚ùå Exception during chat test: {e}")
            self.results["ai_chat"]["status"] = "error"
            self.results["ai_chat"]["details"]["error"] = str(e)
            return False
    
    async def test_kata_lab(self):
        """
        DEEP TEST 4: Kata Lab
        
        Tests whether Kata Lab features actually work:
        - Script Builder: Generates usable scripts
        - Video Compositor: Creates video compositions
        - Synthetic Influencer: Generates AI influencer content
        """
        print("\n" + "="*60)
        print("DEEP TEST 4: Kata Lab Features")
        print("="*60)
        
        kata_results = {
            "script_builder": False,
            "video_compositor": False,
            "synthetic_influencer": False
        }
        
        try:
            # Test Synthetic Influencer (main Kata feature)
            print("\nü§ñ Testing Synthetic Influencer...")
            influencer_response = await self.client.post(
                f"{BASE_URL}/api/kata/synthetic-influencer",
                json={
                    "product_images": ["https://example.com/nike-airmax.jpg"],
                    "product_description": "Nike Air Max 2026 - Revolutionary comfort meets iconic style",
                    "script": "Hey everyone! Check out the new Nike Air Max 2026. The comfort is unreal!",
                    "influencer_style": "energetic",
                    "target_platform": "tiktok",
                    "voice_style": "friendly",
                    "voice_gender": "female"
                },
                headers=self._auth_headers()
            )
            
            if influencer_response.status_code == 200:
                influencer_data = influencer_response.json()
                job_id = influencer_data.get("job_id")
                
                if job_id:
                    print(f"‚úÖ Synthetic influencer job created: {job_id}")
                    print(f"   Status: {influencer_data.get('status')}")
                    kata_results["synthetic_influencer"] = True
                else:
                    print(f"‚ö†Ô∏è Influencer endpoint returned but no job_id")
            else:
                print(f"‚ùå Synthetic influencer failed: {influencer_response.status_code}")
                print(f"   Response: {influencer_response.text[:200]}")
            
            # Test Product Composite
            print("\nüé¨ Testing Product Composite...")
            video_response = await self.client.post(
                f"{BASE_URL}/api/kata/composite-product",
                json={
                    "video_url": "https://example.com/sample-video.mp4",
                    "product_images": ["https://example.com/nike-airmax.jpg"],
                    "product_description": "Nike Air Max 2026",
                    "placement_style": "natural"
                },
                headers=self._auth_headers()
            )
            
            if video_response.status_code == 200:
                video_data = video_response.json()
                job_id = video_data.get("job_id")
                
                if job_id:
                    print(f"‚úÖ Product composite job created: {job_id}")
                    print(f"   Status: {video_data.get('status')}")
                    kata_results["video_compositor"] = True
                else:
                    print(f"‚ö†Ô∏è Video compositor returned but no job_id")
                    print(f"   Response: {video_data}")
            else:
                print(f"‚ùå Product composite failed: {video_response.status_code}")
                print(f"   Response: {video_response.text[:200]}")
            
            # Test Voice Generation
            print("\nüé§ Testing Voice Generation...")
            voice_response = await self.client.post(
                f"{BASE_URL}/api/kata/generate-voice",
                json={
                    "text": "Check out the new Nike Air Max 2026. Revolutionary comfort meets iconic style.",
                    "voice_style": "friendly",
                    "gender": "female"
                },
                headers=self._auth_headers()
            )
            
            if voice_response.status_code == 200:
                voice_data = voice_response.json()
                job_id = voice_data.get("job_id") or voice_data.get("audio_url")
                
                if job_id:
                    print(f"‚úÖ Voice generation job created")
                    print(f"   Response: {voice_data}")
                    kata_results["script_builder"] = True  # Using voice gen as script test
                else:
                    print(f"‚ö†Ô∏è Voice endpoint returned but no job_id")
            else:
                print(f"‚ùå Voice generation failed: {voice_response.status_code}")
                print(f"   Response: {voice_response.text[:200]}")
            
            # Summary
            passed = sum(kata_results.values())
            total = len(kata_results)
            
            print(f"\nüìã Kata Lab Quality Summary:")
            for feature, result in kata_results.items():
                status = "‚úÖ" if result else "‚ùå"
                print(f"   {status} {feature.replace('_', ' ').title()}")
            print(f"\n   Features Working: {passed}/{total}")
            
            self.results["kata_lab"]["status"] = "passed" if passed >= 2 else ("partial" if passed >= 1 else "failed")
            self.results["kata_lab"]["details"] = kata_results
            
            return passed >= 2
            
        except Exception as e:
            print(f"‚ùå Exception during Kata Lab test: {e}")
            self.results["kata_lab"]["status"] = "error"
            self.results["kata_lab"]["details"]["error"] = str(e)
            return False
    
    async def test_deliverables(self):
        """
        DEEP TEST 5: Deliverables
        
        Tests whether actual assets are:
        - Generated and stored
        - Accessible/downloadable
        - Of usable quality
        """
        print("\n" + "="*60)
        print("DEEP TEST 5: Deliverables & Assets")
        print("="*60)
        
        try:
            # Check assets in gallery
            print("\nüñºÔ∏è Checking Asset Gallery...")
            assets_response = await self.client.get(
                f"{BASE_URL}/api/assets?organization_id={self.organization_id}",
                headers=self._auth_headers()
            )
            
            assets = []
            if assets_response.status_code == 200:
                assets_data = assets_response.json()
                assets = assets_data if isinstance(assets_data, list) else assets_data.get("assets", [])
            
            print(f"   Total assets: {len(assets)}")
            
            # Check deliverables from campaign
            print("\nüì¶ Checking Campaign Deliverables...")
            if self.campaign_id:
                deliverables_response = await self.client.get(
                    f"{BASE_URL}/api/campaigns/{self.campaign_id}/deliverables",
                    headers=self._auth_headers()
                )
                
                deliverables = []
                if deliverables_response.status_code == 200:
                    deliverables_data = deliverables_response.json()
                    deliverables = deliverables_data if isinstance(deliverables_data, list) else deliverables_data.get("deliverables", [])
                
                print(f"   Campaign deliverables: {len(deliverables)}")
                
                # Check if deliverables have actual content
                deliverables_with_content = 0
                for d in deliverables:
                    has_content = bool(d.get("content") or d.get("url") or d.get("file_path"))
                    if has_content:
                        deliverables_with_content += 1
                        print(f"   ‚úÖ {d.get('name', 'Unnamed')}: Has content")
                    else:
                        print(f"   ‚ùå {d.get('name', 'Unnamed')}: No content")
            else:
                deliverables = []
                deliverables_with_content = 0
            
            # Try to generate an image asset
            print("\nüé® Testing Image Generation...")
            image_response = await self.client.post(
                f"{BASE_URL}/api/assets/generate",
                json={
                    "organization_id": self.organization_id,
                    "type": "image",
                    "prompt": "Nike Air Max 2026 sneaker, product photography, white background, professional lighting",
                    "style": "photorealistic"
                },
                headers=self._auth_headers()
            )
            
            image_generated = False
            if image_response.status_code == 200:
                image_data = image_response.json()
                image_url = image_data.get("url") or image_data.get("image_url") or image_data.get("asset_url")
                
                if image_url:
                    print(f"‚úÖ Image generated: {image_url}")
                    image_generated = True
                else:
                    print(f"‚ö†Ô∏è Image generation returned but no URL")
            else:
                print(f"‚ùå Image generation failed: {image_response.status_code}")
            
            # Summary
            quality_checks = {
                "has_assets": len(assets) > 0,
                "has_deliverables": len(deliverables) > 0,
                "deliverables_have_content": deliverables_with_content > 0,
                "can_generate_images": image_generated
            }
            
            print(f"\nüìã Deliverables Quality Summary:")
            passed = 0
            for check, result in quality_checks.items():
                status = "‚úÖ" if result else "‚ùå"
                print(f"   {status} {check.replace('_', ' ').title()}")
                if result:
                    passed += 1
            
            quality_score = passed / len(quality_checks)
            print(f"\n   Quality Score: {quality_score*100:.0f}%")
            
            self.results["deliverables"]["status"] = "passed" if quality_score >= 0.5 else "partial"
            self.results["deliverables"]["details"] = {
                "quality_score": quality_score,
                "checks": quality_checks,
                "num_assets": len(assets),
                "num_deliverables": len(deliverables),
                "deliverables_with_content": deliverables_with_content
            }
            
            return quality_score >= 0.5
            
        except Exception as e:
            print(f"‚ùå Exception during deliverables test: {e}")
            self.results["deliverables"]["status"] = "error"
            self.results["deliverables"]["details"]["error"] = str(e)
            return False
    
    async def generate_report(self):
        """Generate final test report"""
        print("\n" + "="*60)
        print("FINAL DEEP FUNCTIONAL TEST REPORT")
        print("="*60)
        
        print(f"\nTest Date: {datetime.now().isoformat()}")
        print(f"Test Brand: {TEST_BRAND['name']} ({TEST_BRAND['website']})")
        
        print("\n" + "-"*40)
        print("RESULTS SUMMARY")
        print("-"*40)
        
        status_emoji = {
            "passed": "‚úÖ",
            "partial": "‚ö†Ô∏è",
            "failed": "‚ùå",
            "error": "üí•",
            "not_tested": "‚è≠Ô∏è"
        }
        
        all_passed = True
        for test_name, result in self.results.items():
            status = result["status"]
            emoji = status_emoji.get(status, "‚ùì")
            print(f"\n{emoji} {test_name.replace('_', ' ').upper()}: {status.upper()}")
            
            if result["details"]:
                for key, value in result["details"].items():
                    if key != "checks":
                        print(f"   {key}: {value}")
            
            if status not in ["passed"]:
                all_passed = False
        
        print("\n" + "-"*40)
        print("OVERALL VERDICT")
        print("-"*40)
        
        if all_passed:
            print("\n‚úÖ PLATFORM IS DELIVERING VALUE")
            print("   All core features are working and producing quality output.")
        else:
            passed_count = sum(1 for r in self.results.values() if r["status"] == "passed")
            partial_count = sum(1 for r in self.results.values() if r["status"] == "partial")
            failed_count = sum(1 for r in self.results.values() if r["status"] in ["failed", "error"])
            
            print(f"\n‚ö†Ô∏è PLATFORM NEEDS WORK")
            print(f"   Passed: {passed_count}")
            print(f"   Partial: {partial_count}")
            print(f"   Failed: {failed_count}")
            
            print("\n   Issues to fix:")
            for test_name, result in self.results.items():
                if result["status"] not in ["passed"]:
                    print(f"   - {test_name}: {result['status']}")
                    if "error" in result["details"]:
                        print(f"     Error: {result['details']['error'][:100]}")
        
        return self.results
    
    async def cleanup(self):
        """Cleanup test resources"""
        await self.client.aclose()


async def main():
    """Run all deep functional tests"""
    print("="*60)
    print("MARKETING AGENT PLATFORM - DEEP FUNCTIONAL TEST")
    print("="*60)
    print("\nThis test verifies the platform DELIVERS VALUE, not just renders pages.")
    print("Testing with real AI operations - this may take several minutes.\n")
    
    tester = DeepFunctionalTest()
    
    try:
        # Setup
        if not await tester.setup():
            print("\n‚ùå Setup failed - cannot continue tests")
            return
        
        # Run all deep tests
        await tester.test_brand_onboarding()
        await tester.test_campaign_execution()
        await tester.test_ai_chat()
        await tester.test_kata_lab()
        await tester.test_deliverables()
        
        # Generate report
        results = await tester.generate_report()
        
        # Save results to file
        with open("deep_test_results.json", "w") as f:
            json.dump(results, f, indent=2, default=str)
        print(f"\nüìÑ Results saved to deep_test_results.json")
        
    finally:
        await tester.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
